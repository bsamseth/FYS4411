\documentclass[Thesis.tex]{subfiles}
\begin{document}
\chapter{Verification and Benchmarking}
\label{chp:verfication}

This chapter is dedicated to presenting some of the tests that we have done to
verify that the software we have developed is indeed functioning as advertised.
These types of tests are more large scale (integration tests) compared to low
level unit tests which is a part of the source code for QFLOW. By checking that
we can reproduce known benchmarks and observe behavior that is consistent with
our expectations we can increase the amount of trust assigned to the implementation.

\section{Setup}

We focus our tests on the idealized harmonic oscillator system in $D = 3$ dimensions
with $N$ non-interacting particles, i.e.\ the Hamiltonian given by
\cref{eq:ho-no-interaction-hamiltonian}:

\begin{align}
    \hat H_0 &= \sum_{i=1}^N\qty(-\frac{1}{2}\laplacian_i +
    \frac{1}{2}r_i^2),
\end{align}
where we have $\hbar = m = \omega = 1$, and
$r_i^2 = x_i^2 + y_i^2+z_i^2$. This has the ground state given by
\cref{eq:Phi-non-inter}, generalized to $N$ particles in three dimension and
omitting normalization constants:

\begin{align}
        \Phi(\mat X) &= \exp[-\frac{1}{2}\sum_{i=1}^N r_i^2],
\end{align}
where as before we have defined $\mat X$ as

\begin{align}
  \mat X &\defeq \mqty(\vx_1\\\vx_2\\\vdots\\\vx_N) \defeq \mqty(x_1&y_1&z_1\\x_2&y_2&z_2\\\vdots&\vdots&\vdots\\x_N&y_N&z_N)
\end{align}

For the trail wave function we shall use two different ones. First, the simple
Gaussian form of the ground state it self:

\begin{align}
  \psi_G(\mat X) = \exp(-\alpha\sum_{i = 1}^N r_i^2),
\end{align}
with $\alpha$ the only variational parameter. Learning the ideal parameters
should be trivial in this case, and we should expect perfect results.

Second, we use an ansatz resulting from a Gaussian-Binary Restricted Boltzmann
Machine (RBM), given in \cref{eq:rbm-def}:


\begin{align}
  \psi_{RBM}(\vX) &=
        \exp[-\sum_i^{M} \frac{\qty(X_i-a_i)^2}{2\sigma^2}]
        \prod_j^H \qty(1 + \exp[b_j+\sum_i^M \frac{X_iW_{ij}}{\sigma^2}]),
\end{align}
where $M = P\cdot D$ is the number of degrees of freedom and $H$ is
the number of hidden nodes (set to 4 through this section). Note also that $X_i$
in the above refers to the $i$'th degree of freedom, counting through $\mat X$
in row major order. The variational parameters are $\vb a, \vb b$ and $\mat W$,
and we hold $\sigma^2=1$ constant in this case.

We use this wave function simply to make learning the true ground state slightly
more challenging than proposing a simple Gaussian straight away. Note that
setting $\vb{a}, \vb b$ and $\mat W$ all to zero yields the correct ground state in this particular case.

\section{Energy Estimates and Statistics}

We start by verifying that we can reproduce expected values for $\expval{E_L}$,
$\expval{r}$ and $\expval{r^2}$ for the ideal harmonic oscillator. We still use
$D=3$ dimensions and set $N=100$ particles.

\cref{tab:verify-energy-estimates} shows the energy obtained using $\psi_G$ with
two different values of $\alpha_G$. For the optimal choice $\alpha_G = 0.5$ we
get the exact analytic ground state energy, $\flatfrac{\expval{E_L}}{N} =
\flatfrac{D}{2}$. The reported variance is entirely due to the limited
precision of $\SI{64}{bit}$ floating point numbers.

For the non-optimal $\alpha_G=0.51$ we get a larger energy, as we would expect.
Furthermore, we get a reported \gls{sem} of $\sim \SI{2e-5}{\au}$. This
includes a correction from the automated blocking mechanism
by~\textcite{Jonsson-2018}. The results were obtained using $2^{23}$ \gls{mc}
samples, so by the standard prescription for \gls{sem} we should have
gotten $\flatfrac{\SI{8e-4}{\au}}{\sqrt{2^{23}}} \approx \SI{3e-7}{\au}$. This
large discrepancy can be explained by the presence of a large amount of
autocorrelation in the energy estimates. Inherent to \gls{mci} is
some degree of autocorrelation, but the reason for this large amount is because
of the large number of particles and how sampling is implemented. Each \gls{mc}
step we move only a single particle. For large $N$ this means it takes a
lot of samples to substantially change the positions of all particles. For smaller
$N$ the correction from blocking is smaller, albeit still present. This
exemplifies the importance of proper calculation of statistical errors. Every
\gls{sem} presented in this thesis will include this correction.


\begin{table}[h]
  \centering
  \caption[Ground state energies of the ideal harmonic oscillator]{\label{tab:verify-energy-estimates}Estimated ground state energy
    using $\psi_G$ with two different values for $\alpha_G$. The energies are
    given per particle, and were produced using \gls{is} and
    $2^{23}$ samples. Statistical errors are corrected for autocorrelation using
    blocking. Energies in atomic units $[\si{\au}]$.\citesource{writing/scripts/verify-energy-stats.py}}
  \input{scripts/verify-energy-stats.py.table1.tex}
\end{table}

Moving from energy to distance metrics, \cref{tab:verify-radius-estimates} shows
the mean radial displacement and its squared sibling for all the particles in the system.
The results were obtained using $\alpha_G=0.5$ and $2^{23}$ \gls{mc} samples. For
reference, the table also states the exact analytic results. Unlike the energy,
which for the ideal $\alpha_G$ is independent of position, these results are not
perfectly accurate. However, the results are correct to five significant digits,
and both $\expval{r}$ and $\expval{r^2}$ are within a few \glspl{sem} from
the analytic value. We take this as further confirmation of both the integration
implementation and the validity of the statistical estimates.

\begin{table}[h]
  \centering
  \caption[Radial metrics of the ideal harmonic oscillator]{\label{tab:verify-radius-estimates}Estimates for the mean radial
    displacement, $\expval{r}$, and the mean squared radial displacement,
    $\expval{r^2}$. For reference the exact analytic results are listed as well
    ($\expval{r}=\flatfrac{2}{\sqrt{\pi\omega}}$ and
    $\expval{r^2}=\flatfrac{D}{2}$), which can be easily verified by computing
    the corresponding integrals directly. Lengths in dimensionless units of $a_{ho}$.\citesource{writing/scripts/verify-energy-stats.py}}
  \input{scripts/verify-energy-stats.py.table2.tex}
\end{table}

\section{One-body Density}

Because the wave functions we typically encounter tend to be multidimensional,
visualizing them can be quite challenging. One way of reducing the
dimensionality is to integrate out the positions for all but one particle. The
result is a \gls{pdf} called the one-body density:

\begin{align}
  \label{eq:one-body-density-def}
  \rho(\vx_1) = \idotsint \dd{\vx_2}\dd{\vx_2}\dots\dd{\vx_N} \abs{\Psi(\vX)}^2,
\end{align}
where we have arbitrarily chosen to keep particle index $1$. This gives the
\gls{pdf} for where one might expect to find particle $1$,
averaged over all possible configurations of the other particles.

As a validating example, we consider the simple Gaussian wave function $\psi_G$.
We get:

\begin{align}
  \rho(\vx_1) &= \idotsint \dd{\vx_2}\dd{\vx_2}\dots\dd{\vx_N} \abs{\psi_G(\vX)}^2\\
  &= e^{-2\alpha r_1^2}\idotsint \dd{\vx_2}\dd{\vx_2}\dots\dd{\vx_N} \,e^{-2\alpha\sum_{i=2}^N r_i^2}\\
    &= C e^{-2\alpha r_1^2},\label{eq:ver-annon-1}
\end{align}
where $C$ is a normalization constant. Perhaps unsurprisingly, the particle will
tend to be located close to the center of the potential well, with exponentially
decreasing probability for increasing radii.

We can perform the integral in \cref{eq:one-body-density-def} for any wave
function using \gls{mci}. We simply make a histogram of the
particles position as we sample a large amount of configuration.\footnote{A
technical caveat is that when we discretize the radius $r_1$ into bins for the
histogram we must account for the different volumes (or areas or lengths in two
and one dimensions) of the bins. Greater $r$ will correspond to greater volumes,
and because of this they will receive a correspondingly greater proportion of
the samples. Dividing the bin counts by their respective volumes fixes this.}
\cref{fig:verify-onebody} shows the resulting plot of $\rho(r_1)$ in a harmonic
oscillator with $N=100$ three-dimensional particles, using $2^{23}$
samples. After normalizing both the result and \cref{eq:ver-annon-1} the two
curves are indistinguishable, showing that our implementation is indeed correct.

\begin{figure}[h]
  \centering
  \resizebox{0.7\linewidth}{!}{%
    \input{scripts/verify-onebody-density.py.tex}
  }
  \caption[One-body density of the ideal harmonic oscillator]{\label{fig:verify-onebody}One-body density of a particle in a
    harmonic oscillator potential, as described by $\psi_G$ with $\alpha=0.5$.
    The curve is indistinguishable from the analytic result. The small
    discrepancy around $r_1=0$ is an artifact of the vanishing volume of the
    inner most bins, and the discrepancy becomes increasingly negligible with
    more samples. This result used $2^{23}$ \gls{mc} samples.\citesource{writing/scripts/verify-onebody-density.py}}
\end{figure}

\section{Two-body Density}

Similarly to the one-body density, we can integrate out all degrees of freedom
except for two particles. This will give us a two-dimensional \gls{pdf} showing
how the two particles are likely to be located relative to each other.

Mathematically we define it in a similar way,

\begin{align}
  \label{eq:two-body-density-def}
  \rho(\vx_1, \vx_2) = \idotsint \dd{\vx_3}\dd{\vx_4}\dots\dd{\vx_N} \abs{\Psi(\vX)}^2,
\end{align}
which for $N$ non-interacting particles governed by $\psi_G$ can be solved
analytically:

\begin{align}
  \label{eq:two-body-analytic}
  \rho(\vx_1, \vx_2) = Ce^{-2\alpha\qty(r_1^2 + r_2^2)}.
\end{align}

Again we can perform the integral numerically using \gls{mci}.
\cref{fig:verify-twobody} shows a contour plot of the density along with the
exact contour lines from \cref{eq:two-body-analytic} indicated by the dashed
lines. Visually distinguishing the two is a little harder now, as we have turned
to colors to visualize the three-dimensional plot. Still, the two sets of
contour lines are very much in agreement, indicating that the implementation is
correct.

\begin{figure}[h]
  \centering
  \resizebox{0.7\linewidth}{!}{%
    \input{scripts/verify-twobody-density.py.tex}
  }
  \caption[Two-body density of the ideal harmonic oscillator]{\label{fig:verify-twobody}Contour plot of the two-body density of
$N=10$ particles in a harmonic oscillator potential, as described by $\psi_G$
with $\alpha=0.5$. The dotted lines are the contours given by
\cref{eq:two-body-analytic}. Again the numerical result follows closely that of
the exact result. This result used $2^{25}$ \gls{mc} samples.\citesource{writing/scripts/verify-twobody-density.py}}
\end{figure}


\section{Optimization}

\subsection{Integration Test}
The simplest complete test is to initialize $\psi_G$ with a non-optimal
parameter, e.g.\ $\alpha=0.3$, and attempt to learn the optimal value.
Optimizing this is trivially accomplished, and
\cref{fig:verify-gaussian-simplest} shows a training progression using $N=10$
particles. The hyperparameters have here been artificially tuned to avoid
immediate convergence to $\alpha =0.5$ so as to better illustrate
the process.

If we allow the training to progress a little further (or use more optimal
hyperparameters), it eventually finds
$\alpha = 0.5$ to within machine precision and we get
$\flatfrac{\expval{E_L}}{N} = \flatfrac{D}{2}$ with exactly zero variance. While
this test is not the most challenging, it is nevertheless a useful check.

\begin{figure}[h]
  \centering
    \resizebox{\linewidth}{!}{%
      \input{scripts/verify-simple-gaussian.py.tex}
    }
  \caption[Learning progression using \gls{vmc} on the ideal harmonic oscillator]{\label{fig:verify-gaussian-simplest}Example training progression using $\psi_G$ as trial wave function.
    Hyperparameters have been tuned so that we can see what happens, as opposed
    to immediate convergence to the perfect result.\citesource{writing/scripts/verify-simple-gaussian.py}}
\end{figure}

\subsection{Learning Rate Dependency}

Successful training is highly dependent on using the correct hyperparameters.
Among the most important are the ones controlling the optimization scheme, such
as the learning rate in Stochastic Gradient Decent (SGD). The following plots
aim to illustrate this dependency, while also serving as a check that the
implemented optimization schemes work as expected.

Importantly, these results are not meant to infer that some schemes or learning
rates are superior to others. Which scheme works best for a given learning
problem will depend on a number of factors, such as the:

\begin{itemize}
  \item Magnitude of the gradients
  \item Number of parameters
  \item Variance in gradient estimates
  \item etc.
\end{itemize}


\subsubsection{Simple Problem - $\psi_G$}

\cref{fig:verify-lr-gaussian} shows the absolute error of $\psi_G$ during
training with several different schemes. For standard SGD we see that a learning
rate around $\eta = 0.1$ performs best among these results, and SGD with $\eta
=0.01$ showing the slowest convergence. Naturally, values of $0.1>\eta>0.01$
perform somewhere between the two.

From these results alone it might seem like
larger learning rates always perform better. To an extent this is true, as it
allows for more rapid learning. However, setting $\eta$ too high can lead to
divergence and unpredictable behavior. In less extreme cases, it can also keep
us from converging properly onto the correct parameters by oscillating around
the ideal values.

We have also included some runs using ADAM. Here we have more parameters to play
with, but only a few are shown here. In this trivial learning example it is hard
to beat properly tuned SGD, but we see how ADAM is able to follow closely. In
this particular case, we saw large improvements by reducing $\beta_1$, which
effectively reduces the momentum applied. An important fact is also that ADAM is
designed to be used with many parameters, with individual learning rates per
parameter. This enhancement does not show itself in this single-parameter example.


\begin{figure}[h]
  \centering
    \resizebox{\linewidth}{!}{%
      \input{scripts/verify-learning-rate-gaussian.py.tex}
    }
  \caption[Comparison of optimization schemes on a simple problem]{\label{fig:verify-lr-gaussian}Example training progression using
    $\psi_G$ as trial wave function with different optimization schemes. With
    sufficient time, all algorithms tend towards zero error.\citesource{writing/scripts/verify-learning-rate-gaussian.py}}
\end{figure}

\subsubsection{More Complex Problem - $\psi_{RBM}$}

We run the same test as above, now with $\psi_{RBM}$ as the trial wave function
instead. We do this to illustrate a common pitfall of gradient based
optimization - local minima. \cref{fig:verify-lr-rbm} shows three runs
plateauing around an error $\sim 10^{-6}\si{\au}$. Interestingly, the worst
result is obtained with the middle most value of $\eta$. This shows the random
nature of SGD, in that it is quite unpredictable when and where we might get
stuck due to a local minimum. Repeating the same experiment with different random
seeds does not consistently reproduce this particular result.

Similarly, we see that one of the ADAM runs did in fact stumble on to a
different, better local minimum. While this is also subject to randomness, we
find that ADAM tends to be at least as good as SGD whenever we have more than
one parameter to learn. This is to be expected, as ADAM can account for
different scales and variability in the components of the parameter gradient.

\begin{figure}[h]
  \centering
    \resizebox{\linewidth}{!}{%
      \input{scripts/verify-learning-rate-rbm.py.tex}
    }
  \caption[Comparison of optimization schemes on a complicated problem]{\label{fig:verify-lr-rbm}Example training progression using
    $\psi_{RBM}$ as trial wave function with different optimization schemes. We
    see evidence of learning getting stuck in local minima due to the overly
    complex wave function anstaz.\citesource{writing/scripts/verify-learning-rate-rbm.py}}
\end{figure}


\section{Sampling}
\label{sec:verify-sampling}

We will now investigate the behavior of the implemented sampling strategies.

\subsection{Step Dependency}

Similarly to the learning rate in optimization schemes, the \gls{mc} samplers
are highly dependent setting an appropriate step parameter. We want to use a
step size that balances two opposing attributes:

\begin{itemize}
\item Particles should be sufficiently mobile.
  \begin{itemize}
  \item Unchanging configurations lead to biased energy estimates with high
    autocorrelation.
  \end{itemize}
\item New configurations should be accepted as much as possible.
  \begin{itemize}
  \item Rejections imply wasted computation time as well as increased autocorrelation.
  \end{itemize}
\end{itemize}


\cref{fig:verify-sampling-step} shows how the \gls{ar} changes with
different step sizes. For both Metropolis and \gls{is}, the \gls{ar} tends
to $\SI{100}{\percent}$ for low step sizes, and to $\SI{0}{\percent}$ for large
values. Both algorithms show a similar pattern in the middle region, with
a steeper decline for \gls{is}. A good trade-off between the above
considerations is achieved when the \gls{ar} is somewhere in the range
\SIrange{50}{99}{\percent}, with the exact best value dependent on the
particular problem at hand.

\begin{figure}[h]
  \centering
    \resizebox{\linewidth}{!}{%
      \input{scripts/verify-sampling-step.py.tex}
    }
    \caption[Comparison of sampling strategies]{\label{fig:verify-sampling-step}\emph{Solid lines:} Acceptance rate of
    Metropolis and \gls{is} as a function of step size. Note that the
  interpretation of the step size is different for the two algorithms. \emph{Dashed
  lines:} \gls{sem} of energy estimates obtained using the corresponding
  sampling algorithm and step size, using $\psi_G$ with $\alpha=0.51$.\citesource{writing/scripts/verify-sampling-step.py}}
\end{figure}


The dotted lines show the \gls{sem} obtained using the
corresponding sampler and step size, when calculating the local energy with
$\psi_G$ and $\alpha=0.51$.\footnote{The value $\alpha=0.51$ was used to avoid
  the zero variance of the ideal value $\alpha=0.5$, but still behaving
  similarly to the real system.} The errors were calculated using $2^{21}$ \gls{mc}
samples and corrected for autocorrelation using blocking~\cite{Jonsson-2018}.

We see Metropolis tending to very small errors in the range shown, with a large
spike around $\delta \approx 0.01$. We believe step sizes around this critical
point allows enough movement for the system to randomly get into unlikely
states, but still so small that getting out of these states takes a long time,
leading to a significant portion of samples from unimportant states. The low
error for both high and low step sizes can be explained by both extremes
resulting in similar behavior; no effective change. When the system remains
unchanged, either from rejected samples or effectively equivalent ones (for high
and low step sizes, respectively), the resulting local energies must necessarily
be very similar as well. Neither case is desirable considering accurate
integration results. Recall that the \gls{sem} is a statistical measure of
the \emph{precision} of the local energy estimate, and not a measure of its
\emph{accuracy}.\footnote{The number $3.14159$ is more precise than the number
$6$, but if the true value is $6.28$, then the latter is more accurate.}\\

\Gls{is} shows different behavior with respect to the \gls{sem}.
For the entire range of good step size choices, \gls{is} results in
smaller statistical errors. This is to be expected, and \gls{is} will
therefore be preferred whenever it is available to us.

Still, we would like to explain the behavior for non-optimal step sizes. The
error shows a spike as the step size decreases, in a similar way as seen for
Metropolis. Although not shown fully, the error also explodes once the
acceptance rate goes below a few percent. We believe this behavior is a result
of how the update rule for \gls{is} is dependent on both the step
size and its square root.

For small step sizes, the square root term will dominate, and the algorithm
effectively decays into standard Metropolis. The location of the spike is
shifted towards smaller step sizes (approximately the square of the Metropolis
spike location), and the spike is wider because the square root function grows
slower than linearly.

Finally, the unstable behavior for large step sizes can be explained the other
way. The little remaining movement is dominated by the drift force, and the
system will quickly get stuck in a local maximum of the wave function, and then be
unable to get out again. These are maxima with large probability amplitudes,
resulting in large values for the local energy and correspondingly large errors.

\end{document}
