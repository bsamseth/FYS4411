\documentclass[Thesis.tex]{subfiles}
\begin{document}
\chapter{Appendices}
\renewcommand{\thesection}{\Alph{section}}
\renewcommand{\thesubsection}{\Alph{section}.\Roman{subsection}}
\crefalias{section}{appsec}

\section{Notation Reference}
\label{app:notation-reference}

This thesis strives to use a consistent set of rules for notation throughout.
Where possible, standard notation choices have been made so as to be easily
comparable to other works. Sometimes, however, we cannot all agree on how things
should be written, and this thesis inevitably diverges from some part of the
readers preferences. In an attempt to soften the inevitable rage of notation
disagreements, this section serves as a reference for all standard
notation used in this thesis, such that the meaning of every expression should
be unambiguous and clear.

\subsection{Symbols}l
\begin{center}
\begin{tabular}{cl}
  Symbol & Reads as\\
  \hline\\
  $=$ & is equal to\\
  $\defeq$ & is defied as\\
  $\equiv$ & is equivalent to\\
  $\disteq$ & is distributed equal to
\end{tabular}
\end{center}

\subsection{Scalars, Vectors and Matrices}

\begin{description}
\item[Scalars:] $x$\hfill\\
  Use lowercase symbols.
\item[Vectors:] $\vx$ \hfill\\
  All vectors are column vectors, and use lowercase, bold-face symbols.
\item[Matrices:] $\mat X$ \hfill \\
  Use uppercase, bold-face symbols.
\end{description}

Example: The matrix $\mat X\in\mathbb{R}^{m\times n}$ is defined by its column
vectors $\{\vx_i\}_{i=1}^n$ (with $\vx_i\in\mathbb{R}^{m}$) such that $ \mat X =
(\vx_1\ \vx_2\ \dots\ \vx_n)$ column vectors, such that the scalar $X_{ij}$ is
the $i$'th component of $\vx_j$.

\subsection{Indices}

Some indices are meant to be summed over, while others remain fixed throughout a
calculation. To help making the distinction between the two, the following
sequences of indices is used for each class, in decreasing order of
precedence:

\begin{description}
\item[Summation indices:] $i, j, a, b, c, d, e, f$
\item[Fixed indices:] $k, l$
\end{description}

\subsection{Summation}

\subsubsection{Scope}

The summation symbol, $\sum$, effects only the term imediately after it. That
is,
\begin{align}
  \sum_{i=1}^3 i + 1 = \qty(\sum_{i=1}^3 i) + 1 = 7, \qq{not} \cancel{\sum_{i=1}^3i + 1 = \sum_{i=1}^3(i + 1) = 9}
\end{align}

\subsubsection{Implied Summations}

For notational brevity (and to avoid visual clutter), summations are not always
stated explicitly as in the above example. In these cases the limits of the
summation are determined by their context.

\begin{description}
\item[Explicit limits:] \hfill\\
  In $\sum_{i=1}^n$, the sum goes from 1 to n, inclusively.
\item[Implicit limits:]\hfill\\
  When limits are clearly defied by their context, the following is equivalent:
  $\sum_{i=1}^n \equiv \sum_{i}^n\equiv \sum_i$.
\item[Implicit summation symbols:]\hfill\\
  We make heavy use of the Einstein summation convention when this is
  appropriate. Any summation index (see above) which appears more than once with
  \emph{a single term} is implicitly summed over all its possible values.
  Superscripts in parenthesis are excluded from this rule, i.e. $a^{(k)}b^{(k)}$
  does not have an implied sum.
\end{description}

Example: Consider the matrix equation $\vb{x} = \mat{A}\vb{b}$, for
$\mat{A}\in\mathbb{R}^{m\times n}$ and $\vx, \vb{b} \in \mathbb{R}^n$. Written
explicitly, all of the following statements about the elements of $\vx$ are equivalent:
\begin{align}
  \begin{split}
  x_k &= \sum_{i=1}^n A_{ki}b_i,\qq{ } x_k = \sum_{i}^n A_{ki}b_i,\\
  x_k &= \sum_{i} A_{ki}b_i,\qq{ } x_k = A_{ki}b_i
  \end{split}
\end{align}

\section{Symmetry Metric}
\label{app:symmetry-metric}

In the context of our Variational Monte Carlo framework, we should in general
take care that the ansatz we make for the functional form of $\Psi_T$ is such
that it obeys \autoref{theorem:spin-statistic}. Not all proposed wavefunctions
will necessary \emph{guarantee} this property, however, and optimization might
find a minima in which this is not true. A such, we shall define a metric to
measure the \emph{symmetry-ness} of a wavefunction.

Before giving a definition, there are a couple of desired properties such a
metric should have.

\begin{enumerate}
    \item Fully symmetric functions should yield a distinct, finite value.
    \item Fully anti-symmetric functions should yield a distinct, finite value,
        which must be different from fully symmetric functions.
    \item Scale invariant, i.e. scaling the function by
        some constant factor does not change its symmetry metric.
    \item Computationally feasible to evaluate.
\end{enumerate}

\begin{definition}{Permutation Operator.}

     Let $\mathcal{P}_n$ denote the set of all permutations of the first $n$
     natural numbers, $\{1, 2, \dots, n\}$, and let $\vec\alpha\in \mathcal{P}_n$
     be one of these. Given a function $\Psi(\vec X_1, \vec X_2,\dots,\vec X_n)$ of
     $n$ vectors $\vec X_i\in \mathbb{R}^f$, we let $P_{\vec\alpha}$ be an
     operator with the following property:

    \begin{align}
        P_{\vec\alpha}\Psi(\vec X_1,\vec X_2,\dots,\vec X_n)
        \defeq
        \Psi(\vec X_{\alpha_1},\vec X_{\alpha_2},\dots,\vec X_{\alpha_n}).
    \end{align}
\end{definition}

\begin{definition}{Symmetry Metric.}

    Given a function $\Psi(\vec X_1, \vec X_2,\dots,\vec X_n)$ of $n$ vectors $\vec
    X_i\in \mathbb{R}^f$. We use the notation $\dd{\vec X}\defeq \dd{\vec X_1}\dots\dd{\vec X_n}$.
    The Symmetry Metric of $\Psi$ is then defined as the following:

    \begin{align}\label{eq:symmetry-metric-def}
        S(\Psi) &\defeq  \ddfrac{\intfy \dd{\vec X}\abs{\frac{1}{n!}
        \sum_{\vec\alpha\in \mathcal{P}_n} P_{\vec\alpha}\Psi}^2}{\intfy\dd{\vec X}
        \max_{\vec\alpha\in \mathcal{P}} \abs{P_{\vec\alpha}\Psi}^2}
    \end{align}
\end{definition}
\begin{corollary}
    The symmetry metric is bounded to the interval $[0, 1]$ for all functions where the integrals are defined.
\end{corollary}
\begin{proof}
    Both the numerator and denominator of \autoref{eq:symmetry-metric-def} are
    integrals of absolute values. Hence they cannot be negative, which proves
    the lower bound $S(\Psi) \geq 0$ for all $\Psi$ where the integrals are defined. Further, the
    absolute value of the average of a set must be less than or equal to the maximum
    absolute value of the set, and equal iff. all values are equal. That is,
    \begin{align}
        \abs{\frac{1}{n!} \sum_{\vec\alpha\in \mathcal{P}_n} P_{\vec\alpha}\Psi}^2
        \leq \max_{\vec\alpha\in \mathcal{P}} \abs{P_{\vec\alpha}\Psi}^2.
    \end{align}
    From this it follows that $S(\Psi) \leq 1$.
\end{proof}
\begin{corollary}
   The symmetry metric is scale invariant, i.e.
    \begin{align}
        S(c\Psi) = S(\Psi),
    \end{align}
    for any scalar $c\in \mathbb{C}$.
\end{corollary}
\begin{proof}
   Obvious.
\end{proof}
\begin{corollary}
    For a symmetric function $\Psi$ we have

    \begin{align}
        S(\Psi) &= 1.
    \end{align}
\end{corollary}
\begin{proof}
    For a symmetric function we have $P_{\vec\alpha}\Psi=\Psi$ for all
    $\vec\alpha\in\mathcal{P}_n$ by definition. The result then follows directly.\end{proof}
\begin{corollary}
    For a anti-symmetric function $\overline\Psi$ we have
    \begin{align}
        S(\overline\Psi)&=0.
    \end{align}
\end{corollary}
\begin{proof}
   Of the $n!$ possible permutations, half can be written as an even number of
    pairwise exchanges, and half as an odd number. This implies
    \begin{align}
        \sum_{\vec\alpha\in \mathcal{P}_n} P_{\vec\alpha}\Psi = 0,
    \end{align}
    and thus the result following from this.
\end{proof}

This definition of the symmetry metric has all the attributes we wanted, except
the computational cost. The asymptotic complexity of $S$ is $\mathcal{O}(n!)$,
which is about as bad as asymptotic complexities get. In addition, the integrals
are many-dimensional and intractable for any non-trivial $n$. In practice we
will therefore approximate $S$ by only considering a random subset of all the
permutations, and of course approximating the integrals with Monte Carlo
integration as before.

This now provides a consistent metric for comparing potential wavefunctions in
terms of their symmetry. This will be helpful when considering trail
wave functions whose functional form does not guarantee symmetry, and to observe
to what extent optimizing them changes the symmetry metric favorably.

\end{document}
