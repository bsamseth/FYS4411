\documentclass[Thesis.tex]{subfiles}
\begin{document}
\chapter{Merging Variational Monte Carlo and Machine Learning}
\label{chp:mergin-vmc-with-ml}

The purpose of Variational Monte Carlo is to find a functions which minimizes
the expected energy of the system. States as such, VMC clearly fits under the
Machine Learning umbrella. Still, it is not a standard Supervised Learning
problem such as linear regression, because we don't have a data set of expected
outputs for every input. Additionally there are some extra challenges introduced
from the quantum problems themselves, such as symmetry requirements and cusp
conditions. I believe these extra challenges are the reason why VMC
optimizations seem to have been done entirely independently of the rest of the
ML research advancements seen in the last few decades.

In more recent years, more and more research seems to go into applying various
techniques from the more general field of ML into VMC. A notable example
is~\textcite{Carleo602}, who demonstrated that a Restricted Boltzmann Machine
(RBM) was capable of representing the wave function for some notable systems to
great effect. I would argue that there still exists a great deal of hesitancy
towards using general models from Machine Learning for VMC. This chapter aims to
enable the use of \emph{any} arbitrary machine learning
model, and in so doing open the door for many new applications and advancements
in the field of VMC.


\section{Discriminative vs. Generative Models}


The RBM used by \textcite{Carleo602} was chosen (partly) because it is a
\emph{generative} model. A distinction is often made between two general types
of ML models:
\emph{discriminative} and \emph{generative}.\footnote{See for instance \textcite{Ng-2001} for
a more in-depth discussion of the topic.} To understand their differences,
imagine we have a data set $\mathcal{D} = \{\vx_i, \vy_i\}_{i=1}^n$ of $n$
inputs $\vx_i$ and outputs $\vy_i$. In general we want to uncover the
relationship between $\vx$ and $\vy$, and we can imagine two different ways of
doing this:

\begin{description}
\item[$p(\vy | \vx)$]\hfill\\
  The conditional probability of $\vy$ given $\vx$.
\item[$p(\vx, \vy)$] \hfill\\
  The joint probability distribution of inputs as outputs.
\end{description}
The most familiar option is the first one. Linear regression is an example of
such a case where we have an input and want to get the corresponding output.
Additionally, instead of considering the probability distribution $p(\vy|\vx)$ we
most often just define the output to be the output with the highest probability,
$\vy = \argmax_{\vy}p(\vb{Y} = \vy | \vX = \vx)$.

Less familiar for most is the second case. Here we model both inputs and outputs
at the same time. Using Bayes rule we can get both $p(\vy|\vx)$ and $p(\vx |
\vy)$ from the joint distribution. This enables us to do not only make predictions of
outputs, but also to generate inputs. This means if we train a generative model
on images of cats and dogs, it could learn to not only classify the images
correctly, but also to generate new images.

\subsubsection{Benefits of a Generative Model}

So what does this have to do with VMC? Our ultimate
goal in VMC to model a probability amplitude for system configurations
$\vX\rightarrow \psi(\vX)$. We want this, in part, so that we can sample
configurations from it. So wouldn't it be nice if we could have the model
generate the configurations directly, instead of having to go through the whole
machinery of the Metropolis-Hastings algorithm and its associated downsides?

When \textcite{Carleo602} used an RBM for their wave function, this opened the
door for new ways of sampling (specifically Gibbs sampling), playing on the
generative nature of the RBM. Such possibilities can improve both computational
performance and accuracy of estimates obtained. It also provides a nice
conceptual link between the model and the generation of configurations.

\subsubsection{Limitations of Generative Models}

While we can in principle obtain the same conditional probabilities of
discriminative models from the joint distribution, it turns out that learning
the joint distribution can be a harder task~\cite{Ng-2001}. This means that
while the result of a generative model has the potential to be more useful, the
increased simplicity of discriminative models can lead to more accurate results.
This is the classic dilemma of whether to do one thing well, or two things
decently. Ideally we would do both, but sometimes the trade off in accuracy is
significant.

Second, and arguably more importantly, limiting ourselves to generative models
is - well, limiting. A vast pool of potential models are discriminative,
including the neural networks from \cref{sec:artificial-neural-networks}. Given
that we have the Metropolis-Hastings algorithm which works excellently is any
most situations, it seems unnecessary to completely disregard some many options.


\section{Arbitrary Models as Trial Wave Functions}

Suppose we propose some arbitrary wave function $\psialpha(\vX)$, parameterized
by an arbitrary number of parameters $\valpha$. Subject to the
requirements on wave functions from \cref{sec:requirements-of-wave-functions},
there are a few things we need from this function in order to successfully run a
VMC optimization. The complete list of required operations is as follows:

\begin{description}
\item[Evaluation:]\hfill\\
  Given a configuration $\vX$, produce a scalar value $\psialpha(\vX)$
\item[Gradient w.r.t. parameters:]\hfill\\
  In order to compute the cost function gradient, we need the following
  quantity:
  \begin{align}
    \label{eq:ml-vmc-operation-gradient}
    \frac{1}{\psialpha(\vX)}\grad_{\valpha}{\psialpha(\vX)} = \grad_{\valpha}{\ln\psialpha(\vX)}
  \end{align}
\item[Gradient w.r.t. inputs:](optional)\hfill\\
  For use with Importance Sampling, we need to compute the drift force
  associated with the wave function (for particle $k$):
  \begin{align}
    \frac{2}{\psialpha(\vX)}\grad_k{\psialpha(\vX)} = 2 \grad_k{\ln\psialpha(\vX)}
  \end{align}
  Note that this is only strictly needed when Importance Sampling is used, and
  can be omitted.
\item[Laplacian w.r.t. inputs:]\hfill\\
  For use with any Hamiltonian which includes kinetic energy, we need to compute
  the Laplacian of the wave function with respect to the configuration $\vX$.
  \begin{align}
    \sum_k\frac{1}{\psialpha(\vX)}\laplacian_k\psialpha(\vX)
  \end{align}
\end{description}

Any function that supports these four operations can be used as a trial wave
function. We should of course take care to choose functions that satisfy the
standard requirements from \cref{sec:requirements-of-wave-functions}, but also
to choose a model which is likely to be a good candidate.

\subsection{Artificial Neural Networks as Trial Wave Functions}

Artificial Neural Networks give us an incredibly flexible way to define
computationally expressive models, and to easily adapt them by changing their
architecture. For a long time, hand crafting Jastrow factors has been the task
of theorists, resulting in (good) trial wave functions rooted in the physics of
the problem. The problem is that hand crafting only goes so far, and we reach
the limits of what we can construct and reason about analytically. Enter now a
way to experiment and play with complex models, in a flexible manner. Using ANNs
could enable us to prototype wave functions more rapidly, as well as possibly
increase the accuracy of the resulting simulations.

Convinced this is a great idea, we have some more working out to do. While
evaluating the output of the network is easy enough (see last chapter), we need
to derive the general expression for the other quantities we need.\\

In the following, let $\psi(\vx)$ be a artificial neural network which has the
quantum numbers of every particle as its inputs. $\vx$ is the concatenation of
all $\{\vx_i\}_{i=1}^N$ for $N$ particles. For our case, that means each
particle coordinate is one input to the network, and the output is the value of
wave function.

\subsubsection{Gradient w.r.t. Parameters}

Back in \cref{sec:ml-backprop} we derived the formulas for the gradient of a
general cost function, with respect to the weights and biases of any network. In
the case of VMC, we need the quantity given in
\cref{eq:ml-vmc-operation-gradient}. We can get this trivially through the
backpropagation algorithm by defining the cost function to be the output of the
network:

\begin{align}
  \mathcal{C}(\psi(\vx)) = \psi(\vx).
\end{align}
Computing the ``cost function'' gradient using backpropagation, we simply divide
by $\psi(\vx)$ to get the quantity in \cref{eq:ml-vmc-operation-gradient}:

\begin{align}
    \frac{1}{\psi(\vX)}\grad_{\valpha}{\psi(\vX)} = \frac{1}{\psi(\vx)}\qty[\grad_{\valpha}{\mathcal{C}(f(\vx))}]
\end{align}

\subsubsection{First Order Partial Derivative w.r.t. inputs}



\subsubsection{Second Order Partial Derivatives w.r.t. inputs}


\end{document}
