import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn
import os
import tempfile
import time

def run_MC(dims=1, n=1, n_mc=100, alpha=0.5, beta=1,
           omega_ho=1, omega_z=1, a=0, h=0.001,
           dt=0.1, step_length=1, importance=True,
           analytic=True):
    """
    Main interface method to the C++ backend.

    Returns an array of energy values generated by the given parameters,
    and a list of numbers printed by the backend program, such as acceptance
    rate, execution time etc.
    """
    options = ('{} '*13).format(int(analytic),
                                int(importance),
                                dims,
                                n,
                                n_mc,
                                alpha,
                                beta,
                                dt,
                                step_length,
                                omega_ho,
                                omega_z,
                                a,
                                h)
    filename = tempfile.mktemp(prefix='run-', suffix='_'.join(options.split(' ')))
    command = '../build-src-Desktop-Release/run_mc.x {} {}'.format(options, filename)
    with os.popen(command) as cmd:
        output = cmd.read()
        output = [float(i) for i in output.strip().split(',')]

    E = np.fromfile(filename, count=n_mc*n, dtype=np.float64)
    return E, output

def E_and_var(**kwargs):
    energies, (_, _, _, _, _, ar, t) = run_MC(**kwargs)
    E_L = np.mean(energies)
    var = np.var(energies)
    return E_L, var

def E_and_var_plot_for_alphas(alphas, dts=(0.1,), verbose=True, saveas=None, **kwargs):
    E   = np.empty((len(dts), len(alphas)))
    var = np.empty((len(dts), len(alphas)))

    for i, dt in enumerate(dts):
        kwargs['dt'] = dt
        for j, alpha in enumerate(alphas):
            kwargs['alpha'] = alpha
            E[i, j], var[i, j] = E_and_var(**kwargs)

    min_E, min_var = np.argmin(E, axis=1), np.argmin(var, axis=1)


    if verbose:
        print(min_E, min_var, np.min(E, axis=1), np.min(var, axis=1))

    # Plot
    fig, ax = plt.subplots(nrows=2, sharex=True, figsize=(12, 12))
    for i, dt in enumerate(dts):
        ax[0].plot(alphas, E[i, :], label=r'$\Delta t={}$'.format(dt))
        ax[0].plot([alphas[min_E[i]]], [E[i, min_E[i]]], 'ro')

        ax[1].plot(alphas, var[i, :])
        ax[1].plot([alphas[min_var[i]]], [var[i, min_var[i]]], 'ro')

    ax[0].set_ylabel(r'$\langle H\rangle$', fontsize=26)
    ax[0].set_title(r'Ground state energy as function of variational parameter $\alpha$', fontsize=22)

    ax[1].set_xlabel(r'$\alpha$', fontsize=26)
    ax[1].set_ylabel(r'$\sigma^2_{E_L}$', fontsize=26)
    ax[1].set_title(r'Variance as function of variational parameter $\alpha$', fontsize=22)


    plt.tight_layout()


    if len(dts) > 1:
        ax[0].legend(loc='upper right', bbox_to_anchor=(0, 0, 0.95, 0.95), fontsize=22)

    if saveas:
        plt.savefig(saveas)

    plt.show()

    return E, var

def proper_error_plot(alphas, saveas=None, **kwargs):
    n = kwargs['n_mc'] * kwargs['n']
    E = np.empty((len(alphas), n))
    for i, alpha in enumerate(alphas):
        kwargs['alpha'] = alpha
        E[i] = run_MC(**kwargs)[0]

    errors = [blocking(e) for e in E]

    fig, ax = plt.subplots(figsize=(12,12))
    ax.errorbar(alphas, np.mean(E, axis=1), yerr=errors)
    ax.set_ylabel(r'$\langle H\rangle$', fontsize=26)
    ax.set_xlabel(r'$\alpha$', fontsize=26)
    ax.set_title(r'Ground state energy as function of variational parameter $\alpha$', fontsize=22)

    if saveas:
        plt.savefig(saveas)

    return E, errors

def make_configuration_table(filename, verbose=True, dims=(1,2,3), ns=(1, 10, 100, 500),
                             analytics=(1, 0), dts=(0.1,), importance=False, **kwargs):

    kwargs['importance'] = importance

    output =  'Dims, Number of particles, Analytic{}, '.format(', Time step' if importance else '')
    output += 'Energy, Variance, Acceptance rate, Time spent\n'

    if verbose:
        print(output, end='')

    fmt = '{0:d}, {1:3d}, {2:3s}, {7:s}{3:4.6e}, {4:4.6e}, {5:4.2f}, {6:7.2e}'

    for d in dims:
        kwargs['dims'] = d
        for n in [1, 10, 100, 500]:
            kwargs['n'] = n
            for analytic in [0, 1]:
                kwargs['analytic'] = analytic
                for dt in dts:
                    kwargs['dt'] = dt

                    E, (_, _, _, _, _, ar, t) = run_MC(**kwargs)

                    energy = np.mean(E)
                    var = np.var(E)

                    imp_fmt = '' if len(dts) == 1 else '{:3.2e}, '.format(dt)
                    line = fmt.format(d, n, 'ON' if analytic else 'OFF', energy, var, ar, t, imp_fmt)

                    if verbose:
                        print(line)

                    output += line + '\n'

    with open(filename, 'w') as f:
        f.write(output)

def E_var_df(alphas, **kwargs):
    E   = np.empty(len(alphas))
    var = np.empty(len(alphas))

    for j, alpha in enumerate(alphas):
        kwargs['alpha'] = alpha
        E[j], var[j] = E_and_var(**kwargs)

    return pd.DataFrame({'alpha': np.asarray(alphas), 'E': E, 'var': var})

def bootstrap(data, statistic, B):
    """
    Return an array of B Bootstrap samples of the given statistic.
    """
    n = len(data)
    theta = np.empty(B)
    for i in range(B):
        theta[i] = statistic(np.random.choice(data, n, replace=True))
    return theta

def blocking(x):
    """
    Return an improved estimate of the standard error
    of the mean of the given time series, accounting for
    covariant samples.

    Code by Marius Jonsson.
    Adapted by Bendik Samseth
    """
    # preliminaries
    n     = len(x)
    d     = int(math.log2(n))
    s     = np.zeros(d)
    gamma = np.zeros(d)
    mu    = np.mean(x)

    # estimate the auto-covariance and variances
    # for each blocking transformation
    for i in range(0, d):
        n = len(x)
        # estimate autocovariance of x
        gamma[i] = np.sum( (x[0:(n-1)] - mu)*(x[1:n] - mu) ) / n
        # estimate variance of x
        s[i] = np.var(x)
        # perform blocking transformation
        x = 0.5 * (x[0::2] + x[1::2])

    # generate the test observator M_k from the theorem
    M = (np.cumsum(((gamma / s)**2 * 2**np.arange(1, d + 1)[::-1])[::-1] ))[::-1]

    # we need a list of magic numbers
    q = np.array([6.634897, 9.210340, 11.344867,
                  13.276704, 15.086272, 16.811894,
                  18.475307, 20.090235, 21.665994,
                  23.209251, 24.724970, 26.216967,
                  27.688250, 29.141238, 30.577914,
                  31.999927, 33.408664, 34.805306,
                  36.190869, 37.566235, 38.932173,
                  40.289360, 41.638398, 42.979820,
                  44.314105, 45.641683, 46.962942,
                  48.278236, 49.587884, 50.892181])

    # use magic to determine when we should have stopped blocking
    for k in range(0, d):
        if M[k] < q[k]:
            break

    if k >= d-1:
        print("Warning: Use more data")

    se = math.sqrt(s[k] / 2**(d - k))
    return se

def time_series_plot(E, saveas=None):
    fig, ax = plt.subplots(figsize=(12, 12))
    ax.plot(E, label=r'$E_L(t)$')
    ax.plot([0, len(E)-1], [np.mean(E)]*2, '--', label=r'$\overline E_L(t)$')
    ax.set_xlabel('Time', fontsize=26)
    ax.set_ylabel(r'$E_L$', fontsize=26)
    plt.legend(loc='best', fontsize=22)

    if saveas:
        plt.savefig(saveas)

    plt.show()



if __name__ == "__main__":
    E_and_var_plot_for_alphas(np.linspace(0.3, 1, 25), n_mc=int(1e4), importance=True, dts=[1, 0.1, 0.001], beta=np.sqrt(1), dims=3, n=1)
